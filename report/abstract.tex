\begin{abstract}
	With the advent of new sophisticated experiment and analysis technology in medicine, the data generation in medicine has accelerated by several folds since the last decades. A big part of all gathered knowledge is the collection of text documents such as research articles. Keeping abreast of biomedical research developments, several efficient natural language processing (NLP) text mining models have also developed. Though, often it is difficult to apply those text mining models directly to domain-specific biomedical corpora. In this project, we combined two different types of NLP models so that the combined model can give a comprehensive answer to cancer-specific questions. At first, we fine-tuned BioBERT (Bidirectional Encoder Representations from Transformers for Biomedical Text Mining)~\cite{10.1093/bioinformatics/btz682} model for short question types over cancer-related question answers and context texts, we called Cancer Ask. Further, we fine-tuned the Generative Pre-trained Transformer 2 (GPT2)~\cite{radford2019language, wolf-etal-2020-transformers}, models over cancer-related text, we named it as GPT2 Cancer. The fundamental objective of this project is to use answers from Cancer Ask, feed it to GPT2 Cancer and provide a comprehensive answer to cancer related queries.
\end{abstract}