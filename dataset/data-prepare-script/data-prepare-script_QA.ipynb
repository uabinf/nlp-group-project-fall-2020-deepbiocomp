{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import xmltodict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading RAW DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/data/user/tr27p/Courses/CS762-NLP/FinalProject/nlp-group-project-fall-2020-deepbiocomp/dataset/raw/1_CancerGov_QA\"\n",
    "\n",
    "DATA_FILES = sorted(os.listdir(DATA_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the list of XML tags in DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['UMLS', 'SemanticGroup', 'Question', 'Answer', 'SemanticType', 'QAPairs', 'CUI', 'QAPair', 'SemanticTypes', 'FocusAnnotations', 'CUIs', 'Focus', 'Document']\n"
     ]
    }
   ],
   "source": [
    "elemList = []\n",
    "for each_file in DATA_FILES:\n",
    "    tree = ET.parse(DATA_DIR+'/'+each_file)\n",
    "    for elem in tree.iter():\n",
    "        elemList.append(elem.tag)\n",
    "\n",
    "elemList = list(set(elemList))\n",
    "\n",
    "print(elemList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing XML to Data Frame with necessary tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_column_names = [\"Focus\", \"SemanticType\", \"SemanticGroup\",\"QType\", \"Question\", \"Answer\"]\n",
    "\n",
    "QA_DATAFRAME = pd.DataFrame(columns = data_column_names)\n",
    "QA_SIZE = 0\n",
    "for each_file in DATA_FILES:\n",
    "    tree = ET.parse(DATA_DIR+'/'+each_file)\n",
    "    root = tree.getroot()\n",
    "    SemanticTypes = []\n",
    "    SemanticGroups = []\n",
    "    QTypes = []\n",
    "    Questions = []\n",
    "    Answers = []\n",
    "    doc_focus = []\n",
    "\n",
    "    for each_passage in root.iter('Document'):\n",
    "        doc_focus.append(each_passage.find('Focus').text)\n",
    "\n",
    "        for each_SemanticType in each_passage.iter('SemanticType'):\n",
    "            SemanticTypes.append(each_SemanticType.text)\n",
    "            \n",
    "        for each_SemanticGroup in each_passage.iter('SemanticGroup'):\n",
    "            SemanticGroups.append(each_SemanticGroup.text)\n",
    "            \n",
    "        for each_Question in each_passage.iter('Question'):\n",
    "            QTypes.append(each_Question.attrib['qtype'])\n",
    "            Questions.append(each_Question.text)\n",
    "            \n",
    "        for each_Answer in each_passage.iter('Answer'):\n",
    "            temp_answer = each_Answer.text.replace('\\n', ' ').replace('\\t', '')\n",
    "            Answers.append(temp_answer)\n",
    "    \n",
    "    doc_df = pd.DataFrame(columns = data_column_names)\n",
    "    if (len(Questions) == len(Answers)):\n",
    "        for index in range(len(Questions)):\n",
    "            if (len(SemanticTypes) == 1):\n",
    "                SemanticType = SemanticTypes[0]\n",
    "            elif (len(SemanticTypes) == 2):\n",
    "                SemanticType = SemanticTypes[0] + ',' + SemanticTypes[1]\n",
    "            temp_df = pd.DataFrame([[doc_focus[0], SemanticType, SemanticGroups[0], QTypes[index], Questions[index], Answers[index]]], columns=data_column_names)\n",
    "            doc_df = doc_df.append(temp_df, ignore_index=True)\n",
    "        QA_SIZE += len(Questions)\n",
    "    QA_DATAFRAME = QA_DATAFRAME.append(doc_df, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting Data Frames to TRAIN(80%), DEV(10%), TEST(10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train datasize (80%)     : 583 \n",
      "+ Validation datasize (10%):  73 \n",
      "+ Test datasize (10%)      :  73 \n",
      " -------------------------------- \n",
      "  Total QA size            : 729\n"
     ]
    }
   ],
   "source": [
    "TRAIN_QA_DATAFRAME = QA_DATAFRAME.sample(frac=0.8,random_state=200)\n",
    "\n",
    "temp_df = QA_DATAFRAME.drop(TRAIN_QA_DATAFRAME.index)\n",
    "DEV_QA_DATAFRAME = temp_df.sample(frac=0.5,random_state=200)\n",
    "\n",
    "TEST_QA_DATAFRAME = temp_df.drop(DEV_QA_DATAFRAME.index)\n",
    "\n",
    "TRAIN_QA_DATAFRAME = TRAIN_QA_DATAFRAME.reset_index(drop=True)\n",
    "DEV_QA_DATAFRAME = DEV_QA_DATAFRAME.reset_index(drop=True)\n",
    "TEST_QA_DATAFRAME = TEST_QA_DATAFRAME.reset_index(drop=True)\n",
    "\n",
    "print(\"  Train datasize (80%)     :\", len(TRAIN_QA_DATAFRAME), \n",
    "      \"\\n+ Validation datasize (10%): \",len(DEV_QA_DATAFRAME),\n",
    "      \"\\n+ Test datasize (10%)      : \", len(TEST_QA_DATAFRAME), \n",
    "      \"\\n\", \"-\"*32, \"\\n\", \n",
    "      \" Total QA size            :\", QA_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Data frames to Tab Separated File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPARED_DATA_PATH ='/data/user/tr27p/Courses/CS762-NLP/FinalProject/nlp-group-project-fall-2020-deepbiocomp/dataset/prepared-data/qa/'\n",
    "\n",
    "TRAIN_QA_TSV = PREPARED_DATA_PATH + 'train_qa.tsv'\n",
    "DEV_QA_TSV = PREPARED_DATA_PATH + 'dev_qa.tsv'\n",
    "TEST_QA_TSV = PREPARED_DATA_PATH + 'test_qa.tsv'\n",
    "\n",
    "TRAIN_QA_DATAFRAME.to_csv(TRAIN_QA_TSV, sep='\\t', index=False)\n",
    "DEV_QA_DATAFRAME.to_csv(DEV_QA_TSV, sep='\\t', index=False)\n",
    "TEST_QA_DATAFRAME.to_csv(TEST_QA_TSV, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Data Frames to JSON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reff: https://stackabuse.com/reading-and-writing-json-to-a-file-in-python/\n",
    "def dataFrame_to_json(DataFrame_name, OutPut_json_file_name):\n",
    "    QA_JSON = {}\n",
    "\n",
    "    QA_JSON['qas'] = []\n",
    "    for index in range(len(DataFrame_name)):\n",
    "        QA_JSON['qas'].append({\"index\": index, \"Focus\": DataFrame_name.Focus[index],\n",
    "                                     \"Focus\": DataFrame_name.Focus[index], \n",
    "                                     \"SemanticType\": DataFrame_name.SemanticType[index], \n",
    "                                     \"SemanticGroup\": DataFrame_name.SemanticGroup[index], \n",
    "                                     \"QType\": DataFrame_name.QType[index], \n",
    "                                     \"Question\" : DataFrame_name.Question[index], \n",
    "                                     \"Answer\" : DataFrame_name.Answer[index]})\n",
    "        \n",
    "    with open(OutPut_json_file_name, 'w') as outfile:\n",
    "        json.dump(QA_JSON, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving JSON data to JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_QA_JSON = PREPARED_DATA_PATH + 'train_qa.json'\n",
    "DEV_QA_JSON = PREPARED_DATA_PATH + 'dev_qa.json'\n",
    "TEST_QA_JSON = PREPARED_DATA_PATH + 'test_qa.json'\n",
    "\n",
    "dataFrame_to_json(TRAIN_QA_DATAFRAME, TRAIN_QA_JSON)\n",
    "dataFrame_to_json(DEV_QA_DATAFRAME, DEV_QA_JSON)\n",
    "dataFrame_to_json(TEST_QA_DATAFRAME, TEST_QA_JSON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert RAW XML to JSON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reff: https://www.geeksforgeeks.org/python-xml-to-json/\n",
    "def XML_to_json(XML_file_name, OutPut_json_file_name):\n",
    "    with open(XML_file_name) as xml_file: \n",
    "        data_dict = xmltodict.parse(xml_file.read()) \n",
    "        xml_file.close()\n",
    "        \n",
    "        json_data = json.dumps(data_dict) \n",
    "        \n",
    "        with open(OutPut_json_file_name, \"w\") as json_file: \n",
    "            json_file.write(json_data) \n",
    "            json_file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_JSON_DATA_PATH = \"/data/user/tr27p/Courses/CS762-NLP/FinalProject/nlp-group-project-fall-2020-deepbiocomp/dataset/raw/1_CancerGov_QA_JSON\"\n",
    "\n",
    "for each_file in DATA_FILES:\n",
    "    source = DATA_DIR+'/'+each_file\n",
    "    each_file = each_file.split('.')[0]\n",
    "    destination = RAW_JSON_DATA_PATH+'/'+each_file+'.json'\n",
    "    XML_to_json(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
